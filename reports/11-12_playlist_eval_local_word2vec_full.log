nohup: ignoring input
2017-11-12 12:14:40,652 - summa.preprocessing.cleaner - INFO - 'pattern' package not found; tag filters are not available for English
2017-11-12 12:14:40,689 - __main__ - INFO - started playlist eval with config: {'dataDir': 'data/full_model/', 'outDir': 'data/rec_all/', 'SHOULD_GENERATE_GRAPH': False, 'SHOULD_INDEX_ES': False, 'TEST_PLAYLIST_SPLIT': 0.2, 'PRECISION_AT': [1, 10, 15], 'USE_USER_IN_QUERY': True, 'SHOULD_EMBED': False, 'ARGS': Namespace(album=True, genre=True, tags=True)}
2017-11-12 12:14:40,689 - __main__ - INFO - %%% playlist_eval runner... 
2017-11-12 12:14:40,923 - __main__ - INFO - %%% ge calc initializing... 
2017-11-12 12:14:40,923 - gensim.models.keyedvectors - INFO - loading projection weights from data/rec_all/deepwalk.em
2017-11-12 12:16:25,006 - gensim.models.keyedvectors - INFO - loaded (1546303, 64) matrix from data/rec_all/deepwalk.em
2017-11-12 12:16:29,337 - __main__ - INFO - %%% ge calc initializing done in 108.413s


2017-11-12 12:16:29,337 - __main__ - INFO - ------------- evaluation -------------
2017-11-12 12:16:29,337 - __main__ - INFO - %%% evaluation... 
2017-11-12 12:16:29,337 - gemsearch.evaluation.playlist_query_evaluator - INFO - Started playlist evaluation with 4159 playlists
2017-11-12 12:16:29,361 - gensim.models.keyedvectors - INFO - precomputing L2-norms of word weight vectors
2017-11-12 14:59:53,110 - gemsearch.evaluation.playlist_query_evaluator - INFO - Playlist evaluation finished: total 4159 playlists (testsplit=0.2)
[{'key': 'rec_tracks_with_user@1',
  'values': {'avg_hits': 0.006732387593171436,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 28,
             'precision': 0.006732387593171436,
             'precision_on_has_hits': 1.0,
             'recall': 0.00011632739209040788}},
 {'key': 'rec_tracks_with_user@15',
  'values': {'avg_hits': 0.12094253426304401,
             'avg_hits_on_has_hits': 2.053061224489796,
             'has_hits': 245,
             'precision': 0.008062835617536254,
             'precision_on_has_hits': 0.13687074829931953,
             'recall': 0.002368343111716159}},
 {'key': 'rec_tracks_with_user@10',
  'values': {'avg_hits': 0.08199086318826641,
             'avg_hits_on_has_hits': 1.8042328042328042,
             'has_hits': 189,
             'precision': 0.008199086318826656,
             'precision_on_has_hits': 0.18042328042328074,
             'recall': 0.0017257181287478503}},
 {'key': 'rec_query_tracks_with_user@15',
  'values': {'avg_hits': 0.8239961529213753,
             'avg_hits_on_has_hits': 3.0408163265306123,
             'has_hits': 1127,
             'precision': 0.05493307686142478,
             'precision_on_has_hits': 0.20272108843537326,
             'recall': 0.048022951376838284}},
 {'key': 'rec_query_tracks_with_user@10',
  'values': {'avg_hits': 0.5890839144025006,
             'avg_hits_on_has_hits': 2.5257731958762886,
             'has_hits': 970,
             'precision': 0.05890839144024965,
             'precision_on_has_hits': 0.2525773195876271,
             'recall': 0.035431358938880664}},
 {'key': 'rec_multiple_queries_tracks_with_user@15',
  'values': {'avg_hits': 1.1608559749939888,
             'avg_hits_on_has_hits': 4.046940486169321,
             'has_hits': 1193,
             'precision': 0.07739039833293203,
             'precision_on_has_hits': 0.2697960324112861,
             'recall': 0.07247045044211806}},
 {'key': 'rec_multiple_queries_tracks_with_user@10',
  'values': {'avg_hits': 0.8639095936523202,
             'avg_hits_on_has_hits': 3.348555452003728,
             'has_hits': 1073,
             'precision': 0.08639095936523226,
             'precision_on_has_hits': 0.3348555452003737,
             'recall': 0.05622083419447982}},
 {'key': 'rec_query_tracks_with_user@1',
  'values': {'avg_hits': 0.08824236595335418,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 367,
             'precision': 0.08824236595335418,
             'precision_on_has_hits': 1.0,
             'recall': 0.0057960925773736845}},
 {'key': 'rec_first_two_query_tracks_with_user@15',
  'values': {'avg_hits': 1.508776148112527,
             'avg_hits_on_has_hits': 4.517638588912887,
             'has_hits': 1389,
             'precision': 0.10058507654083439,
             'precision_on_has_hits': 0.3011759059275235,
             'recall': 0.09233010390213177}},
 {'key': 'rec_multiple_queries_tracks@15',
  'values': {'avg_hits': 1.6794902620822314,
             'avg_hits_on_has_hits': 6.089799476896251,
             'has_hits': 1147,
             'precision': 0.11196601747214835,
             'precision_on_has_hits': 0.4059866317930819,
             'recall': 0.10436424183784743}},
 {'key': 'rec_first_two_query_tracks_with_user@10',
  'values': {'avg_hits': 1.1291175763404664,
             'avg_hits_on_has_hits': 3.7329093799682034,
             'has_hits': 1258,
             'precision': 0.11291175763404729,
             'precision_on_has_hits': 0.3732909379968225,
             'recall': 0.07211148895039844}},
 {'key': 'rec_multiple_queries_tracks_with_user@1',
  'values': {'avg_hits': 0.11324837701370521,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 471,
             'precision': 0.11324837701370521,
             'precision_on_has_hits': 1.0,
             'recall': 0.007863051298580953}},
 {'key': 'rec_first_two_query_tracks@15',
  'values': {'avg_hits': 1.842269776388555,
             'avg_hits_on_has_hits': 5.804545454545455,
             'has_hits': 1320,
             'precision': 0.12281798509256979,
             'precision_on_has_hits': 0.38696969696969524,
             'recall': 0.11473489080165684}},
 {'key': 'rec_first_two_query_tracks_with_user_scaled@15',
  'values': {'avg_hits': 1.8766530415965377,
             'avg_hits_on_has_hits': 5.75165806927045,
             'has_hits': 1357,
             'precision': 0.125110202773102,
             'precision_on_has_hits': 0.3834438712846951,
             'recall': 0.11716734946770962}},
 {'key': 'rec_multiple_queries_tracks@10',
  'values': {'avg_hits': 1.293339745131041,
             'avg_hits_on_has_hits': 4.930339138405133,
             'has_hits': 1091,
             'precision': 0.1293339745131045,
             'precision_on_has_hits': 0.4930339138405147,
             'recall': 0.08490889415358883}},
 {'key': 'rec_query_tracks_with_user_scaled@15',
  'values': {'avg_hits': 2.0331810531377736,
             'avg_hits_on_has_hits': 6.348348348348348,
             'has_hits': 1332,
             'precision': 0.13554540354251834,
             'precision_on_has_hits': 0.4232232232232236,
             'recall': 0.12743486758129574}},
 {'key': 'rec_first_two_query_tracks_with_user@1',
  'values': {'avg_hits': 0.1370521760038471,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 570,
             'precision': 0.1370521760038471,
             'precision_on_has_hits': 1.0,
             'recall': 0.009175044276105604}},
 {'key': 'rec_query_tracks@15',
  'values': {'avg_hits': 2.0569848521279153,
             'avg_hits_on_has_hits': 6.667965705378021,
             'has_hits': 1283,
             'precision': 0.13713232347519452,
             'precision_on_has_hits': 0.4445310470252019,
             'recall': 0.12808858988766111}},
 {'key': 'rec_first_two_query_tracks@10',
  'values': {'avg_hits': 1.399615292137533,
             'avg_hits_on_has_hits': 4.683024939662108,
             'has_hits': 1243,
             'precision': 0.13996152921375357,
             'precision_on_has_hits': 0.4683024939662117,
             'recall': 0.09189208373412541}},
 {'key': 'rec_first_two_query_tracks_with_user_scaled@10',
  'values': {'avg_hits': 1.4140418369800434,
             'avg_hits_on_has_hits': 4.660063391442155,
             'has_hits': 1262,
             'precision': 0.1414041836980045,
             'precision_on_has_hits': 0.4660063391442161,
             'recall': 0.0930824455269098}},
 {'key': 'rec_first_two_query_tracks_mean@15',
  'values': {'avg_hits': 2.153642702572734,
             'avg_hits_on_has_hits': 6.272408963585434,
             'has_hits': 1428,
             'precision': 0.14357618017151574,
             'precision_on_has_hits': 0.41816059757236274,
             'recall': 0.13344035923544814}},
 {'key': 'rec_query_tracks_with_user_scaled@10',
  'values': {'avg_hits': 1.550132243327723,
             'avg_hits_on_has_hits': 5.141148325358851,
             'has_hits': 1254,
             'precision': 0.15501322433277276,
             'precision_on_has_hits': 0.5141148325358866,
             'recall': 0.10200355454862413}},
 {'key': 'rec_query_tracks@10',
  'values': {'avg_hits': 1.5686463092089444,
             'avg_hits_on_has_hits': 5.35632183908046,
             'has_hits': 1218,
             'precision': 0.15686463092089498,
             'precision_on_has_hits': 0.5356321839080478,
             'recall': 0.10320216250264819}},
 {'key': 'rec_multiple_queries_tracks@1',
  'values': {'avg_hits': 0.16229862947823998,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 675,
             'precision': 0.16229862947823998,
             'precision_on_has_hits': 1.0,
             'recall': 0.011374424685420529}},
 {'key': 'rec_first_two_query_tracks_mean@10',
  'values': {'avg_hits': 1.62827602789132,
             'avg_hits_on_has_hits': 5.023738872403561,
             'has_hits': 1348,
             'precision': 0.16282760278913255,
             'precision_on_has_hits': 0.5023738872403578,
             'recall': 0.10645149621662456}},
 {'key': 'rec_first_two_query_tracks@1',
  'values': {'avg_hits': 0.1709545563837461,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 711,
             'precision': 0.1709545563837461,
             'precision_on_has_hits': 1.0,
             'recall': 0.01186949375131069}},
 {'key': 'rec_first_two_query_tracks_with_user_scaled@1',
  'values': {'avg_hits': 0.17143544121182977,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 713,
             'precision': 0.17143544121182977,
             'precision_on_has_hits': 1.0,
             'recall': 0.011996566394677147}},
 {'key': 'rec_album_or_query@15',
  'values': {'avg_hits': 2.573695599903823,
             'avg_hits_on_has_hits': 8.515513126491646,
             'has_hits': 1257,
             'precision': 0.17157970666025524,
             'precision_on_has_hits': 0.5677008750994443,
             'recall': 0.1633717492743653}},
 {'key': 'rec_query_tracks_with_user_scaled@1',
  'values': {'avg_hits': 0.1904303919211349,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 792,
             'precision': 0.1904303919211349,
             'precision_on_has_hits': 1.0,
             'recall': 0.013150851105643081}},
 {'key': 'rec_query_tracks@1',
  'values': {'avg_hits': 0.1937965857177206,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 806,
             'precision': 0.1937965857177206,
             'precision_on_has_hits': 1.0,
             'recall': 0.013412680427488857}},
 {'key': 'rec_album_or_query@10',
  'values': {'avg_hits': 1.9538350565039673,
             'avg_hits_on_has_hits': 6.715702479338843,
             'has_hits': 1210,
             'precision': 0.19538350565039708,
             'precision_on_has_hits': 0.6715702479338855,
             'recall': 0.13175701174538632}},
 {'key': 'rec_first_two_query_tracks_mean@1',
  'values': {'avg_hits': 0.2017311853811012,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 839,
             'precision': 0.2017311853811012,
             'precision_on_has_hits': 1.0,
             'recall': 0.013902935058505204}},
 {'key': 'rec_album_or_query@1',
  'values': {'avg_hits': 0.21880259677807165,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 910,
             'precision': 0.21880259677807165,
             'precision_on_has_hits': 1.0,
             'recall': 0.015309155516850756}}]
2017-11-12 14:59:53,117 - __main__ - INFO - %%% evaluation done in 9803.779s


------------- done -------------
2017-11-12 14:59:53,382 - __main__ - INFO - %%% playlist_eval runner done in 9912.692s


