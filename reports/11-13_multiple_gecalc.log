nohup: ignoring input
2017-11-13 09:41:21,924 - summa.preprocessing.cleaner - INFO - 'pattern' package not found; tag filters are not available for English
2017-11-13 09:41:21,957 - __main__ - INFO - started playlist eval with config: {'dataDir': 'data/model_multiple_artists/', 'outDir': 'data/rec_multiple_artists/', 'SHOULD_GENERATE_GRAPH': False, 'SHOULD_INDEX_ES': True, 'TEST_PLAYLIST_SPLIT': 0.2, 'PRECISION_AT': [1, 10, 15], 'USE_USER_IN_QUERY': True, 'SHOULD_EMBED': False, 'ARGS': Namespace(album=True, data_dir='data/model_multiple_artists/', genre=True, out_dir='data/rec_multiple_artists/', tags=True)}
2017-11-13 09:41:21,957 - __main__ - INFO - %%% playlist_eval runner... 
2017-11-13 09:41:22,212 - __main__ - INFO - %%% elastic search writer... 
all indexes cleared
{'_shards': {'failed': 0, 'successful': 5, 'total': 5}, 'count': 1447014}
2017-11-13 09:43:20,414 - __main__ - INFO - %%% elastic search writer done in 118.202s


2017-11-13 09:43:20,415 - __main__ - INFO - %%% ge calc initializing... 
2017-11-13 09:44:07,241 - __main__ - INFO - %%% ge calc initializing done in 46.826s


2017-11-13 09:44:07,241 - __main__ - INFO - ------------- evaluation -------------
2017-11-13 09:44:07,241 - __main__ - INFO - %%% evaluation... 
2017-11-13 09:44:07,242 - gemsearch.evaluation.playlist_query_evaluator - INFO - Extract queries from playlist names (result is cached)
2017-11-13 09:47:40,590 - gemsearch.evaluation.playlist_query_evaluator - INFO - For evaluation 2324 of 2399 playlists are left
2017-11-13 09:47:40,592 - gemsearch.evaluation.playlist_query_evaluator - INFO - Started playlist evaluation with 2324 playlists
2017-11-13 13:11:38,588 - gemsearch.evaluation.playlist_query_evaluator - INFO - Playlist evaluation finished: total 2324 playlists (testsplit=0.2)
[{'key': 'rec_tracks_with_user@10',
  'values': {'avg_hits': 0.18631669535283993,
             'avg_hits_on_has_hits': 1.9330357142857142,
             'has_hits': 224,
             'precision': 0.018631669535284046,
             'precision_on_has_hits': 0.193303571428572,
             'recall': 0.0031986862639288164}},
 {'key': 'rec_tracks_with_user@15',
  'values': {'avg_hits': 0.28012048192771083,
             'avg_hits_on_has_hits': 2.3003533568904593,
             'has_hits': 283,
             'precision': 0.018674698795180775,
             'precision_on_has_hits': 0.15335689045936438,
             'recall': 0.004672057458894807}},
 {'key': 'rec_tracks_with_user@1',
  'values': {'avg_hits': 0.019793459552495698,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 46,
             'precision': 0.019793459552495698,
             'precision_on_has_hits': 1.0,
             'recall': 0.0003819888152361055}},
 {'key': 'rec_query_tracks_with_user@15',
  'values': {'avg_hits': 0.4229776247848537,
             'avg_hits_on_has_hits': 2.573298429319372,
             'has_hits': 382,
             'precision': 0.028198508318990387,
             'precision_on_has_hits': 0.1715532286212923,
             'recall': 0.00847577153442534}},
 {'key': 'rec_query_tracks_with_user@1',
  'values': {'avg_hits': 0.028399311531841654,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 66,
             'precision': 0.028399311531841654,
             'precision_on_has_hits': 1.0,
             'recall': 0.000545937632735776}},
 {'key': 'rec_query_tracks_with_user@10',
  'values': {'avg_hits': 0.28399311531841653,
             'avg_hits_on_has_hits': 2.156862745098039,
             'has_hits': 306,
             'precision': 0.02839931153184172,
             'precision_on_has_hits': 0.21568627450980443,
             'recall': 0.005729274462150422}},
 {'key': 'rec_multiple_queries_tracks_with_user@15',
  'values': {'avg_hits': 0.45654044750430295,
             'avg_hits_on_has_hits': 2.6133004926108376,
             'has_hits': 406,
             'precision': 0.030436029833620336,
             'precision_on_has_hits': 0.1742200328407233,
             'recall': 0.010932163154266676}},
 {'key': 'rec_multiple_queries_tracks_with_user@10',
  'values': {'avg_hits': 0.31712564543889843,
             'avg_hits_on_has_hits': 2.2607361963190185,
             'has_hits': 326,
             'precision': 0.03171256454388987,
             'precision_on_has_hits': 0.22607361963190203,
             'recall': 0.007811593154120173}},
 {'key': 'rec_multiple_queries_tracks_with_user@1',
  'values': {'avg_hits': 0.03571428571428571,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 83,
             'precision': 0.03571428571428571,
             'precision_on_has_hits': 1.0,
             'recall': 0.0009917284438477798}},
 {'key': 'rec_first_two_query_tracks_with_user@15',
  'values': {'avg_hits': 0.6123063683304647,
             'avg_hits_on_has_hits': 3.0084566596194504,
             'has_hits': 473,
             'precision': 0.04082042455536437,
             'precision_on_has_hits': 0.2005637773079636,
             'recall': 0.015156854698407864}},
 {'key': 'rec_first_two_query_tracks_with_user@10',
  'values': {'avg_hits': 0.4259896729776248,
             'avg_hits_on_has_hits': 2.481203007518797,
             'has_hits': 399,
             'precision': 0.042598967297762406,
             'precision_on_has_hits': 0.24812030075187927,
             'recall': 0.01077866155797077}},
 {'key': 'rec_first_two_query_tracks_with_user@1',
  'values': {'avg_hits': 0.047332185886402756,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 110,
             'precision': 0.047332185886402756,
             'precision_on_has_hits': 1.0,
             'recall': 0.0013551800248214133}},
 {'key': 'rec_multiple_queries_tracks@15',
  'values': {'avg_hits': 0.8115318416523236,
             'avg_hits_on_has_hits': 5.579881656804734,
             'has_hits': 338,
             'precision': 0.05410212277682158,
             'precision_on_has_hits': 0.371992110453649,
             'recall': 0.0318016998918233}},
 {'key': 'rec_query_tracks_with_user_scaled@15',
  'values': {'avg_hits': 0.8537005163511188,
             'avg_hits_on_has_hits': 3.9919517102615694,
             'has_hits': 497,
             'precision': 0.056913367756741245,
             'precision_on_has_hits': 0.2661301140174379,
             'recall': 0.026025812416703098}},
 {'key': 'rec_multiple_queries_tracks@10',
  'values': {'avg_hits': 0.5946643717728055,
             'avg_hits_on_has_hits': 4.359621451104101,
             'has_hits': 317,
             'precision': 0.05946643717728044,
             'precision_on_has_hits': 0.43596214511040926,
             'recall': 0.024578117620960467}},
 {'key': 'rec_query_tracks_with_user_scaled@10',
  'values': {'avg_hits': 0.5972461273666093,
             'avg_hits_on_has_hits': 3.3126491646778042,
             'has_hits': 419,
             'precision': 0.0597246127366607,
             'precision_on_has_hits': 0.33126491646777917,
             'recall': 0.018748482254399196}},
 {'key': 'rec_query_tracks_with_user_scaled@1',
  'values': {'avg_hits': 0.06497418244406196,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 151,
             'precision': 0.06497418244406196,
             'precision_on_has_hits': 1.0,
             'recall': 0.0022335574521949496}},
 {'key': 'rec_first_two_query_tracks_with_user_scaled@15',
  'values': {'avg_hits': 1.0098967297762478,
             'avg_hits_on_has_hits': 4.228828828828829,
             'has_hits': 555,
             'precision': 0.06732644865174978,
             'precision_on_has_hits': 0.28192192192192156,
             'recall': 0.03349390940659898}},
 {'key': 'rec_query_tracks@15',
  'values': {'avg_hits': 1.064974182444062,
             'avg_hits_on_has_hits': 6.6,
             'has_hits': 375,
             'precision': 0.07099827882960406,
             'precision_on_has_hits': 0.4399999999999996,
             'recall': 0.04415802971922154}},
 {'key': 'rec_first_two_query_tracks_with_user_scaled@10',
  'values': {'avg_hits': 0.7207401032702238,
             'avg_hits_on_has_hits': 3.439425051334702,
             'has_hits': 487,
             'precision': 0.07207401032702211,
             'precision_on_has_hits': 0.34394250513346897,
             'recall': 0.024805230147278413}},
 {'key': 'rec_first_two_query_tracks@15',
  'values': {'avg_hits': 1.0873493975903614,
             'avg_hits_on_has_hits': 6.193627450980392,
             'has_hits': 408,
             'precision': 0.07248995983935737,
             'precision_on_has_hits': 0.4129084967320258,
             'recall': 0.043841037744571966}},
 {'key': 'rec_query_tracks@10',
  'values': {'avg_hits': 0.7758175559380379,
             'avg_hits_on_has_hits': 5.093220338983051,
             'has_hits': 354,
             'precision': 0.07758175559380368,
             'precision_on_has_hits': 0.5093220338983044,
             'recall': 0.033912994451885406}},
 {'key': 'rec_first_two_query_tracks@10',
  'values': {'avg_hits': 0.8042168674698795,
             'avg_hits_on_has_hits': 4.918421052631579,
             'has_hits': 380,
             'precision': 0.0804216867469879,
             'precision_on_has_hits': 0.4918421052631575,
             'recall': 0.034071628365888694}},
 {'key': 'rec_multiple_queries_tracks@1',
  'values': {'avg_hits': 0.08261617900172118,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 192,
             'precision': 0.08261617900172118,
             'precision_on_has_hits': 1.0,
             'recall': 0.003881570834099716}},
 {'key': 'rec_album_or_query@15',
  'values': {'avg_hits': 1.2435456110154905,
             'avg_hits_on_has_hits': 8.027777777777779,
             'has_hits': 360,
             'precision': 0.082903040734366,
             'precision_on_has_hits': 0.5351851851851849,
             'recall': 0.05395691755037685}},
 {'key': 'rec_first_two_query_tracks_with_user_scaled@1',
  'values': {'avg_hits': 0.08433734939759036,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 196,
             'precision': 0.08433734939759036,
             'precision_on_has_hits': 1.0,
             'recall': 0.0031816039200858273}},
 {'key': 'rec_album_or_query@10',
  'values': {'avg_hits': 0.8919965576592083,
             'avg_hits_on_has_hits': 6.06140350877193,
             'has_hits': 342,
             'precision': 0.08919965576592073,
             'precision_on_has_hits': 0.6061403508771923,
             'recall': 0.04059793513305786}},
 {'key': 'rec_first_two_query_tracks@1',
  'values': {'avg_hits': 0.10413080895008606,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 242,
             'precision': 0.10413080895008606,
             'precision_on_has_hits': 1.0,
             'recall': 0.00474579427394643}},
 {'key': 'rec_query_tracks@1',
  'values': {'avg_hits': 0.10456110154905336,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 243,
             'precision': 0.10456110154905336,
             'precision_on_has_hits': 1.0,
             'recall': 0.00495376249616596}},
 {'key': 'rec_album_or_query@1',
  'values': {'avg_hits': 0.10843373493975904,
             'avg_hits_on_has_hits': 1.0,
             'has_hits': 252,
             'precision': 0.10843373493975904,
             'precision_on_has_hits': 1.0,
             'recall': 0.005114408007426986}}]
2017-11-13 13:11:38,594 - __main__ - INFO - %%% evaluation done in 12451.353s


------------- done -------------
2017-11-13 13:11:39,097 - __main__ - INFO - %%% playlist_eval runner done in 12617.14s


